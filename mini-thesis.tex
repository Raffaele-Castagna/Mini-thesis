\documentclass[11pt, a4paper]{article}
\usepackage[utf8]{inputenc} % comment when using lualatex
\usepackage{amsmath, amsthm, amssymb, calrsfs, verbatim, bbm, color, graphics, geometry}
%\usepackage[italian]{babel} % lingua e a-capo-sillabato
\usepackage{fullpage}
\usepackage{graphicx}
%\usepackage[hidelinks]{hyperref,xcolor} % link di pagina
\usepackage[bottom]{footmisc} % note appiccicate al fondo della pagina
\usepackage{float} % per posizionamento immagini

\geometry{tmargin=.75in, bmargin=.75in, lmargin=.75in, rmargin = .75in}  

\usepackage[backend=bibtex]{biblatex}
\addbibresource{mini-thesis.bib}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Cdot}{\boldsymbol{\cdot}}

\newtheorem{thm}{Theorem}
\newtheorem{defn}{Definition}
\newtheorem{conv}{Convention}
\newtheorem{rem}{Remark}
\newtheorem{lem}{Lemma}
\newtheorem{cor}{Corollary}



\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}


\title{Exploring statistical techniques for threat detection and AI security}
\author{Raffaele Castagna}

\date{Statistics Academic Year 2025-2026}

\begin{document}

\maketitle
\tableofcontents

\newpage
\nocite{*}
\section{Introduction}
Cybersecurity has always been shaped by data analysis, ever since its inception. Even at the start when the \textit{fortress model} was the optimal choice, sysadmins typically relied on the binary classification
of traffic, files and behaviours that were either safe or were known malicious patterns, but to actually analyze a file most relied on static analysis of signatures, where the hash of a file was computed and then denoted as malicious, this could also be applied to
byte sequences in network traffic or to generalize even more IP ranges could be blocked, either based on suspicious activity or on countries. Under the hood there was a statistical assumption: the distribution of malicious behaviour was disjointed from the distribution of normal behaviour, and therefore there was a boundary between the two that was immutable.\\\\
However with the continued expansion of the internet, and the users therein, this assumption became obsolete, the world has changed and with it the amount of data that is ingested, take for example Industrial Control systems or autonomous vehicles navigating public roads\cite{paper},in these kinds of environments the amount of data and heterogenity of the devices make signature based maintenance an impossible task. Expanding on this, the convergence of IT and OT (Operational Technology) has exposed critical industrial machine to a wide area of attack,
and therefore shifted what can be considered normal behaviour, as well as the attack surface.\cite{AnDetection}\\\\
With these new surfaces, the entire landscape changed, particularly with the rise of APT (Advanced Persistent Threats), which can even be state-sponsored threats, that are particularly interested in IO, these APTs usually utilize a technique called "living off the land" which
utilizes legitimate software and functions to carry out their attacks, e.g. utilizing group policy changes to gain persistance and access to restricted controls and information, another type of vulnerability that is continuedly exploited are Zero-Day attacks, which due to their nature are impossible to defend against with static hashing, so there's a need to 
move to a dynamic analysis of behaviour, which is where statistics come into play, so that we see a threat as something that \textit{deviates from a probabilist baseline}, this is what in the modern cyberseucurity field is called \textbf{statistical anomaly detection}\cite{AdSurvey}.\\\\
Anomaly detection is rooted in the statistical hypothesis that malicious activity is rare and different from normal activity. It does not ask, "Is this specific packet known to be bad?" but rather, "What is the probability that this packet belongs to the distribution of normal traffic observed over the last month?" This shift requires security professionals to abandon binary certainty in favor of probabilistic reasoning. It demands a rigorous understanding of distributions, variance, and correlation. The security analyst of the future must be as fluent in covariance matrices and p-values as they are in firewalls and encryption protocols.
\subsection{The Dual Role of Artificial Intelligence: Tool and Target}
As statistical methods evolved, they gave rise to Machine Learning (ML) and Artificial Intelligence (AI), which are essentially statistical inference engines operating at scale. AI has become a powerful tool for defense, capable of ingesting terabytes of log data to identify subtle correlations that are impossible to spot for a human analysts\cite{MLsurvey}.AI-driven statistical anomaly detection has been shown to outperform traditional analytical techniques in mitigating cybersecurity risks in complex environments like wireless networks\cite{StatAn}.\\\\
However, this reliance on AI introduces a recursive vulnerability: the statistical models themselves are now targets. We are witnessing the rise of Adversarial Machine Learning (AML), where attackers exploit the probabilistic nature of AI. By carefully crafting inputs that are statistically indistinguishable from benign data to a human but catastrophic to a model's mathematical logic, attackers can blind surveillance systems or cause autonomous vehicles to misinterpret stop signs\cite{OnTheStats}\cite{PaloAlto1}.\\\\
Thus, the domain of AI security is not merely about securing the software code but about securing the statistical inference process. It involves using advanced statistical tests such as Kernel Density Estimation (KDE), Maximum Mean Discrepancy (MMD), and Benford’s Law to detect when a distribution is being manipulated. The defender must now monitor the monitor, applying statistical tools to ensure that the AI systems protecting the network are not themselves compromised by statistical illusions.\\\\
\section{Statistical Anomaly Detection in Network Security}
Network intrusion detection is the practice of monitoring network traffic for suspicious activity and unauthorized access. While rule-based systems (e.g. Snort) look for known byte sequences, statistical anomaly detection techniques build a model of what is considered 
"normal" traffic for a network and flags certain deviations. This approach has been widely used since the 2000s, and is currently being amplified by the use of AI.
\subsection{Gaussian Assumption and Univariate Analysis}
To be able to distinguish normal from anomalous traffic we must assume that normality exists. The Gaussian distribution (or what we called the normal distribution) is essential for anomaly detection because it's a mathematically convenient way to define what we consider normal. In a normal distribution, around $~68\%$ of data points fall within one standard deviation (SD, $\sigma$) or the mean ($\mu$), $95\%$ within 2 SDs and $99.7\%$ within 3 SDs. Therefore we can
statistically define anomalies as those data points that are statistically improbable, e.g. \textit{p} $ < 0.0003$.\\\\
In the simplest scenario a security analyst may apply \textbf{univariate analysis} to examine a single variable in isolation, take for example the CPU load of a database server, to do so we have multiple ways:
\begin{itemize}
    \item \textbf{Grubb's test} The statistical test is used to detect a single outlier in an univariate dataset that follows a normal distribution\cite{AdSurvey}. It calculates a $G$ statistic based on the difference between the maximum deviation and the mean.
    \item \textbf{Z-score} Modern systems utilizing the Z-score, which normalizes a data point $x$ by subtracting the mean and dividing by the standard deviation $Z=\frac{x-\mu}{\sigma}$. If the Z-score is greater than 3 this indicates that the data point is an outlier.
\end{itemize}
But, as we learned, univariate analysis is limited, and for modern cybersecurity applications it is insufficient, if we were to analyze data points like "high outbound network traffic", this might be benign, for example we could be doing an update or a backup, but if an attacker were to be using a low speed or low bandwidth exfiltration technique, they would stay within normal bounds ($< 2\sigma$), and even if we direct it to an unusual IP address at an unusual time, we are not analyzing this variable and therefore we ignore that. So multivariate analysis is something that isn't needed but required for cybersecurity applications.\cite{Mahalanobis}
\subsection{Multivariate Analysis and Mahalanobis Distance}
In network analysis, variables are often correlated, take, for example, the number of packets, it is typically correlated with the number of bytes transferred, if we were to rely on euclidean distance (which assumes independence), we might not see anomalies that arise when the relationship is broken.\\\\
For a more practical example, consider a server that typically sends small packets (high packet count but small number of bytes for each packet) or large file transfers (high count and high packet count). If an attacker were to try and perform a buffer overflow attack, he would send a small number of extremely large packets, if we were to map this into an Euclidean space, this point might still be close to the center of a data cloud, but it has almost no \textbf{correlation} to usual traffic.\\\\
To actually solve this we use \textbf{Mahalanobis Distance}, which measures the distance between a point $P$ and a distribution $D$, effectively it measures how many standard deviations away $P$ is from the mean of $D$, while also accounting for the covariance among the variables.\cite{Mahalanobis}\cite{AnPayload}\\\\
The Mahalanobis distance $D_M$ of an observation vector $x = (x_1, x_2, ..., x_n)^T$  from a set of observations with mean vector $\mu = (\mu_1, \mu_2, ..., \mu_n)^T$ and covariance matrix $\Sigma$ is defined as:$$ D_M(\mathbf{x}) = \sqrt{ (\mathbf{x} - \boldsymbol{\mu})^T \mathbf{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu}) } $$
where:
\begin{itemize}
    \item $\mathbf{x}$ is the feature vector of the incoming traffic (packet length, inter-arrival time, port number).
    \item $\boldsymbol{\mu}$ is the mean vector calculated from the normal training data
\end{itemize}
The term $\Sigma^{-1}$ either whitens or decorrelates data, if two variables typically vary together (so we have an high covariance) the matrix $\Sigma$ captures this. By multiplying the inverse we penalize deviations that go against the known correlation structures.\\\\
For example, if Variable A and Variable B usually increase together, a data point where A is high and B is low will result in a large Mahalanobis distance, identifying it as an anomaly even if the individual values of A and B are within their respective normal ranges.\\\\
\subsection{Payload Detection}
Mahalanobis distance has been used to detect anomalies in packet payloads, systems like PAYL compute the byte frequency distribution of incoming payloads and compare them to a historical profile. It is then given a score (refered to as the "distance") and if for example the payload contains a shellcode or exploit, this would alter the natural frequency of bytes found in ASCII text or common protocols, and therefore gives us a higher distance.\\\\
The decision is typically governed by a threshold $\tau$:
$$
\text{Status}(\mathbf{x}) = \begin{cases}
    \text{Anomaly} & \text{if } D_M(\mathbf{x}) > \tau \\
    \text{Normal} & \text{if } D_M(\mathbf{x}) \le \tau
\end{cases}
$$
Because the squared mahalanobis distance of a Gaussian vector still follows a Chi-squared distribution with $n$ degrees of freedom where $n$ is the number of dimensions, the threshold $\tau$ can be rigorously derived from Chi-squared tables for whatever significance level is desired.\cite{Mahalanobis}
\subsection{Dimensionality Reduction and PCA}
A problem that arises when using any high dimensionality dataset, be for statistics or machine learning is the \textbf{curse of dimensionality}, as the number of features (dimensions) increases, the computational cost of inverting the covariance matrix ($\Sigma^{-1}$) becomes prohibitive ($O(n^3)$), and the data becomes sparse, so distance measuring becomes less impactful.\\\\
To counteract this we use \textbf{Principal Component Analysis}  (PCA), which uses an orthogonal transformation to covnert a set of data points that are possibly correlated with each other into a set of values of linearly uncorrelated variables which are then called \textit{principal components}. The first principal component has the largest possible variance (so it accounts for as much of the variability in the data as possible), and each succeeding component has the highest variance possible under the constraint that it is orthogonal to the preceding components.\\\\
One of the main ways PCA is used in to visualize the clustering of malware families, most malware analysis often involves extracting thousands of features, this would be impossible manually, but even with powerful computers analyzing this raw data is expensive and difficult to visualize withouth the help of PCA and other dimensionality reduction techniques.\\\\
Using PCA we can project high dimensionality data into lower dimensionality spaces (2D or 3D) while preserving the maximum variance. This reveals the underlying clusters of data present in malware families\cite{VisualMalware}, to be more precise:
\begin{itemize}
    \item \textbf{Clustering}: Different Malware families (e.g. ransomware, trojans, worms) often exhibit distinct behavioral patterns. When projected into a lower-dimensional space using PCA, these patterns can form separate clusters, making it easier to identify and categorize malware samples.
    \item \textbf{Anomaly Detection}: PCA can also help identify outliers or novel malware variants that do not fit into existing clusters. These anomalies may represent new threats that require further investigation.
\end{itemize}
Nowadays, we combine PCA with other techniques and clustering algorithms like K-MEANS and ART2 (Adaptive Resonance Theory) to visualize malware families. The spatial alignment of color-coded clusters in PCA space corresponds to true malware families, proving that the statistical variance capture by PCA corresponds to the function differences in malware code.\cite{ART2}
\begin{center}
    \includegraphics[width=0.8\textwidth]{images/Clustering-ART2-visualisation-using-Principal-Component-Analysis-PCA-with-a-After.png}
\end{center}
As shown in the image above, PCA plots often show lines or trajectories within clusters, these can represent the evolution of a malware family over time (e.g. Racoon Stealer), this allows for the tracking of the genealogy of threats.\cite{VisualMalware}
\subsection{Industrial Control Systems and Operational Technology applications}
These statistical methods are particularly useful in ICS and OT, which both prioritize availability over confidentiality, in these kind of networks we can identify 3 major anomalies:
\begin{itemize}
    \item \textbf{Cyber Anomalies}: Old-fashioned intrusions.
    \item \textbf{Operation Anomalies}: System malfunctions or misconfigurations.
    \item \textbf{Service Disruptions}: Availability issues.
\end{itemize}
The convergence of IT and OT means that industrial networks are now exposed to a wider range of threats. However, OT traffic is often more regular and deterministic than IT traffic (e.g., a sensor polling a valve every 500ms). This regularity actually makes statistical anomaly detection highly effective. Deviations from the strict, deterministic patterns of industrial protocols (like Modbus or DNP3) are easier to detect using statistical baselines than the chaotic traffic of a corporate web network.\cite{AnDetection}


\section{Time Series Analysis for Network Forecasting}
While multivariate looks at the relationships between different variables, \textbf{time series analysis} is focused on the relationship between a variable and its past self, network traffic is temporal, and it exhibits trends alongside seasonality and noise, during a normal work day you would normally receive similar day-to-day traffic. So anomaly detection is also a forecasting problem, our statistical model should be able to predict what the traffic should look like at time $t$, based on previously known data,
the anomaly detection system will then compare this prediction $\hat{Y_t}$ with the observed value $Y_t$, if the error $e_t = |Y_t - \hat{Y_t}|$ exceeds a threshold, then it is considered anomalous, and in turn an alert is raised.\cite{AnDetectionNep}\cite{ARIMAAnDec}\\\\
\subsection{ARIMA Models}
\textbf{Auto Regressive Integrated Moving Average} models are widely used for statistical time series forecasting, due to its robust mathematical foundations and the ability to decompose traffic signals into predictable variations and noise.\cite{ARIMAAnDec}\\\\
An ARIMA model is characterized by the parameters $(p,d,q)$\cite{ARIMAWikipedia}:
\begin{itemize}
    \item $p$ (Auto-Regressive order): The number of times the raw observations are differenced to make the signal stationary.
    \item $d$ (Integrated order): The number of times the raw observations are differenced to make the signal stationary.
    \item $q$ (Moving Average order): The size of the moving average windows, which captures the relationship between the current observation and past errors.
\end{itemize}
The general equation for an ARIMA($p,d,q$) model is essentially a linear regression of the
current value against past values and past errors. Using the lag operator $B$ (where $B X_t = X_{t-1}$), it is expressed as:
$$\phi(B) (1 - B)^d X_t = \theta(B) \epsilon_t$$
\begin{itemize}
    \item $\phi(B) = 1 - \phi_1 B - \dots - \phi_p B^p$ is the autoregressive polynomial.
    \item $\theta(B) = 1 + \theta_1 B + \dots + \theta_q B^q$ is the moving average polynomial.
    \item $(1 - B)^d$ represents the differencing operation performed $d$ times.
    \item $\epsilon_t$ is the white noise error term\cite{ARIMAWikipedia}
\end{itemize}
A prerequisite for ARIMA models it is stationarity, we say that a time series is stationary if its statistical properties (mean,variance,autocorrelation) are constant over time. But network traffic is rarely stationary, most of the time there's a trend or change of variance.\\
So to solve this we use the Integrated $d$ component, which performs differencing.\cite{I2ARIMA} \cite{ARIMAAnDec}:\\\\
If $d=1$, the model analyzes the change between consecutive points $Y'_t = Y_t -Y_{t-1}$. This removes linear trends.\\
If $d=2$, it analyzes the change of the changes, removing quadratic trends.
Most network traffic analysis uses $d=1$ to account for traffic drift.\cite{I2ARIMA}\\\\
To actually detect anomalies ARIMA models follow these steps:
\begin{itemize}
    \item Training: Fitting the parameters $(\phi, \theta)$ on a window of "clean" historical traffic.
    \item Forecasting: Predicting the next value $\hat{X}_{t+1}$.
    \item Residual Analysis: Calculating the error $e_{t+1} = X_{t+1} - \hat{X}_{t+1}$
    \item Thresholding: If the error is significantly large (e.g., outside the 95\% confidence interval of the prediction), it indicates that the underlying process generating the traffic has changed—likely due to an attack like a DDoS (Distributed Denial of Service) or a massive data exfiltration.
\end{itemize}
\subsection{Seasonal ARIMA (SARIMA) and ISP variability}
Network traffic is seasonal, with the peaks being in the evening (referred to as "streaming hours"), while Corporate traffic peaks in the morning, an ARIMA model might interpret this as an anomaly, therefore to need to account for seasonality, we can extend the ARIMA model to include seasonal components, resulting in the Seasonal ARIMA (SARIMA) model. We
denote SARIMA as ARIMA$(p,d,q) \times(P,D,Q)_s$, where $s$ is the length of the season (e.g., 24 for hourly data). The modelincludes seasonal autoregressive and moving average terms:
$$\Phi_P(B^s) \phi(B) \nabla_s^D \nabla^d X_t = \Theta_Q(B^s) \theta(B) w_t$$
This allows our model to correlate traffic at different times,which is esssential for ISPs. Newer Deep Learning models like LSTM (Long Short-Term Memory) are also being experimented upon due to the fact that they can model non-linear temporal dependencies, but ARIMA remains competitive and has an entire ecosystem built around it. If we were to compare them ARIMA is optimal for most cases while ML DL models are useful in complex environments.\cite{CESNET}\cite{AKvelon}\cite{ARIMAReview}
\section{Bayesian Statistics}
As we've seen in the previous sections, ARIMA deals with temporal trends, but we also need a way to deal with uncertainty and causality, most of the time defenders do not see an attack directly, but rather evidence of it, Bayesian statistics provides us with a framework to update the probability of a breach as we find new evidence.\\\\
The biggest challenge in intrusion detection is being able to distinguish true threats from false positives, we can use Bayes' Theorem to calculate the posterior probability of an attack given an alerts:
$$P(\text{Attack} | \text{Alert}) = \frac{P(\text{Alert} | \text{Attack}) \cdot P(\text{Attack})}{P(\text{Alert})}$$
This formula highlights what we call the \textbf{base rate fallacy}, even if our Intrusion Detection System (IDS) is highly accurate (high $P(\text{Alert} | \text{Attack})$), if the probability of an actual attack $P(\text{Attack})$ is very low, the posterior probability of an attack given an alert may still be low due to high number of benign events.\\\\
Suppose that only 1 in 10,000 events is an attack, a system with a 1\% false positive rate will generate 100 false alarms for every 10,000 legitimate events, and the single real attack will be under a mountain of noise. By applying Bayesian analysis security teams account explicitly for these priors and help tune the system to optimize the \textbf{Positive Predictive Value}, rather than raw detection rates.\\\\
\subsection{Bayesian Networks and Attack Graphs}
Usually attacks come one after another, as an initial breach only widens the surface area for further attacks, a \textbf{Bayesian Network} is a probabilistic graphical model that represents a set of variables and their conditional dependencies via a DAG. We can further specialize these graphs into what we call \textit{Bayesian Attack Graphs}, where nodes represent system states or vulnerabilities, and edges represent the exploits that transition the attacker from one state to another.\\\\
Bayesian Attack Graphs allow for the calculation of Reachability Probabilities, the likelihood that an attacker can reach an asset from a certain state.\\\\
The Static Reachability Probability $P_b(S_i)$ of a node $S_i$ depends on the successful compromise of its parent nodes and the exploitability of the vulnerability itself.\cite{BayesianAttackGraphs}
Nodes may have a relationship between each:
\begin{itemize}
    \item AND Relationship (All preconditions must be met):\\
    \[
        P_b(S_i) = P_a(S_i) \cdot \prod_{j=1}^{n} P_b(\text{parent}_j)
    \]
    Here, $P_a(S_i)$ represents the intrinsic probability of exploiting the vulnerability (often derived from CVSS scores).
    \item OR Relationship (Any precondition suffices): $$P_b(S_i) = P_a(S_i) \cdot \left( \text{any precondition probability} \right)$$.
\end{itemize}
However though this is useful to understand the subject, these rules are static, and in a real world scenario we need to adapt them to be dynamic, so that it may work even while an attack progresses, therefore we need \textbf{Dynamic Reachability}.\\\\
If an IDS detects a webserver that has been/is being exploited ($P(S_{web})=1$), this value propagates through the network, dramatically increasing the probability of compromise for downstream nodes.\\
The dynamic reachability $P_c(S_j | S_i)$ (probability of parent $S_j$ given child $S_i$ is compromised) involves inverse probabilistic reasoning\cite{BayesianAttackGraphs}:
$$P_c(S_j | S_i) = P(S_i | S_j) \cdot \frac{P_b(S_j)}{P_b(S_i)}$$
This allows IDS that incorporate Bayesian Attack Graphs to predict the next most likely targets of an attacker and tighten defences.
\subsection{K2 and Junction Trees}
Actually querying the graphs (and networks) built by this algorithms is computationally expensive, therefore we use \textbf{K2 algorithm}, an heuristic search method used to learn the structure of Bayesian Networks from data. The algoritm starts from a single node and incrementally adds parents that maximize the network's posterior probability, dealing effectively with incomplete records in security logs\cite{InDectSystemBayesian}.
Once we have actually built the structure of the Bayesian Network, we can use \textbf{Junction Tree Inference} to actually calculate the probabilities. This algorithm transforms the Bayesian Netowrk intro a tree structure where exact inference is tractable. This allows for the efficient propagation of alerts through the graph to update all probabilities simultaneously.\cite{InDectSystemBayesian}
\subsection{Parameter Learning and Dirichlet Distributions}
We still need to define the conditional probabilities in the nework, therefore we need to estimate parameters ($\theta$) from data. Since attack data is spare we estimate this data using a \textbf{Dirichlet Distribution}, which is the conjugate prior to the multinomial distribution.
The posterior mean for a probability parameter $p$, given prior count $K\lambda$ and observed data count $N$, is\cite{InDectSystemBayesian}:
$$E(p | \text{data}) = \frac{N}{N+K} \left( \frac{x}{N} \right) + \frac{K}{N+K} \lambda$$
This formula balances the observed empirical frequency ($x/N$) with the prior belief ($\lambda$). In the early stages we have a small $N$, and the system relies on the prior data from previous engagements. As more data is collected (large $N$), the systems begins to rely on that data. This estimator based on Bayes is mostly needed to stabilize detection systems against the volatility of small samples.
\subsection{Naive Bayes Classifiers}
To better our spam filters and malware classifiers we can use \textbf{Naive Bayes Classifiers}, which simplifies calculations by assuming that all features are conditionally independent given the class, an assumption which is false most of the time, but its effective\cite{NaiveBayesWikipedia}.\\\\
The classification rule maximizes the posterior probability:
$$\hat{y} = \operatorname*{argmax}_{k \in \{1, \dots, K\}} P(C_k) \prod_{i=1}^{n} P(x_i | C_k)$$
Recently, Naive Bayes Classifiers have been modified to address the Zero Probability problem (where a never-before-seen word creates a probability of 0, wiping out the entire calculation) by changing multiplication operations to addittion or eliminating zero-probability variables.



\newpage
\printbibliography


\end{document}